{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2ca3c1-b849-464d-ae9e-e336be8217b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6caff19-58a8-4f8b-b42e-f92cf26354b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format, so each element\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea9f028-977f-4b00-860a-7fcf627955f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = '65k_64_56'\n",
    "\n",
    "BASE_DIR        = f\"../data/MAR2_al/MAR2_hpl/{cores}/\"   # point this at the “14” folder\n",
    "DATA_DIR        = f\"../results/{cores}/\"\n",
    "\n",
    "OUT_G           = f\"../results/{cores}/G_matrix.csv\"\n",
    "OUT_T           = f\"../results/{cores}/Ta_vector.csv\"\n",
    "OUT_P           = f\"../results/{cores}/Pij.csv\"\n",
    "OUT_f           = f\"../results/{cores}/fij.csv\"\n",
    "\n",
    "# Number of DVFS states to detect via clustering\n",
    "DVFS_STATES     = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0de047-d6b8-4b66-ba83-f9e020ff4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load a sample MAR2_hpl round -------------------\n",
    "def load_round_pkl(base_dir, round_name=\"round0\"):\n",
    "    \"\"\"\n",
    "    Load the roundX.pkl for a given HPL configuration\n",
    "    \"\"\"\n",
    "    pkl_path = os.path.join(base_dir, round_name, \"preprocessing\", f\"{round_name}.pkl\")\n",
    "\n",
    "    print(pkl_path)\n",
    "    \n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# ─────────────────────  PACKAGE → PER‑CORE POWER  ──────────────────────────\n",
    "\n",
    "def safe_package_power(\n",
    "    energy_df: pd.DataFrame,\n",
    "    dt: float,\n",
    "    rapl_units_j: float | None = None,\n",
    "    modulus: int | None = None,\n",
    "    max_pkg_watts: float = 400.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert monotonic RAPL energy counters -> package power (W) robustly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    energy_df : DataFrame (T×P)\n",
    "        Raw cumulative energy counters (as read from MSR), one column per package.\n",
    "    dt : float\n",
    "        Sampling interval in seconds.\n",
    "    rapl_units_j : float, optional\n",
    "        If the raw counter units are *not* joules, pass the conversion factor.\n",
    "        Example: Intel MSR_RAPL_UNIT gives 1 LSb = 15.3e-6 J by default.\n",
    "        If None we assume the DataFrame is already in joules.\n",
    "    modulus : int, optional\n",
    "        Counter modulus for wrap‑around (e.g. 2**32 or 2**48).  If None,\n",
    "        wrap detection is skipped.\n",
    "    max_pkg_watts : float\n",
    "        Any single‑sample power delta above this is treated as bad data and dropped.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Series length T\n",
    "        Package power in Watts (sum over all package columns, cleaned).\n",
    "    \"\"\"\n",
    "    E = energy_df.copy()\n",
    "\n",
    "    # 1) optional unit conversion\n",
    "    if rapl_units_j is not None:\n",
    "        E *= rapl_units_j\n",
    "\n",
    "    # 2) unwrap counters\n",
    "    if modulus is not None:\n",
    "        diff = E.diff()\n",
    "        wrapped = diff < 0\n",
    "        E[wrapped] += modulus * rapl_units_j if rapl_units_j else modulus\n",
    "\n",
    "    diff = E.diff().fillna(0)\n",
    "    P_pkg = diff.sum(axis=1) / dt  # combine packages -> Watts\n",
    "\n",
    "    # 3) drop negative or implausibly large spikes\n",
    "    P_pkg[(P_pkg < 0) | (P_pkg > max_pkg_watts)] = np.nan\n",
    "    # interpolate small gaps, forward‑fill last resort\n",
    "    P_pkg = P_pkg.interpolate(limit_direction=\"both\")\n",
    "\n",
    "    return P_pkg\n",
    "\n",
    "def package_power_watts(data: dict, dt: float = 0.5) -> pd.Series:\n",
    "    \"\"\"Convert RAPL energy counters (J) → package power (W).\"\"\"\n",
    "    pkg_erg = data[\"power_from_erg_pkg_cpu\"]  # T×P energy (J)\n",
    "\n",
    "    raw_E = data[\"power_from_erg_pkg_cpu\"]      # T×P\n",
    "    pkg_power_W = safe_package_power(\n",
    "    raw_E,\n",
    "    dt=0.5,                 # your sample period\n",
    "    rapl_units_j=15.3e-6,   # or None if already Joules\n",
    "    modulus=2**32           # adjust if 48‑bit\n",
    "    )\n",
    "\n",
    "    \n",
    "    return pkg_power_W  # Series (T samples)\n",
    "\n",
    "def per_core_power(\n",
    "    pkg_power: pd.Series,\n",
    "    data: dict,\n",
    "    bar_p: float = 2.64,\n",
    "    active_thresh: float = 0.5,\n",
    "    med_k: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Split package power across *active* cores only (C0 residency > threshold).\n",
    "    Adds the idle baseline `bar_p` to every core.\n",
    "    Optionally median‑filters the result (`med_k` must be odd; 1 = no filter).\n",
    "    \"\"\"\n",
    "    cores = data[\"temp_core\"].columns\n",
    "    c0 = data[\"C0_norm_tsc_core\"] > active_thresh\n",
    "    power = pd.DataFrame(index=pkg_power.index, columns=cores, dtype=float)\n",
    "\n",
    "    for t in pkg_power.index:\n",
    "        active = c0.loc[t]\n",
    "        n_active = active.sum()\n",
    "        if n_active == 0:\n",
    "            power.loc[t] = bar_p\n",
    "        else:\n",
    "            residual = pkg_power.loc[t] - bar_p * len(cores)\n",
    "            share = residual / n_active\n",
    "            power.loc[t, active] = bar_p + share\n",
    "            power.loc[t, ~active] = bar_p\n",
    "\n",
    "    if med_k > 1:\n",
    "        power = power.apply(medfilt, kernel_size=med_k)\n",
    "    return power\n",
    "\n",
    "def estimate_bar_p(data: dict, dt: float = 0.5, idle_thresh: float = 0.05) -> float:\n",
    "    \"\"\"\n",
    "    Estimate per‑core idle power BAR_P (Watts) from roundX.pkl contents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict\n",
    "        The dictionary loaded from roundX.pkl (contains 'power_from_erg_pkg_cpu',\n",
    "        'C0_norm_tsc_core', etc.).\n",
    "    dt : float\n",
    "        Sampling period in seconds (default 0.5 s).\n",
    "    idle_thresh : float\n",
    "        Core is considered idle if C0 residency ≤ `idle_thresh`\n",
    "        (e.g. ≤ 5 % of the 0.5‑s window).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bar_p : float\n",
    "        Estimated idle power per core in Watts.\n",
    "    \"\"\"\n",
    "    # 1) Package power in Watts (sum across packages)\n",
    "    pkg_energy_J = data[\"power_from_erg_pkg_cpu\"]      # shape T×P (Joules)\n",
    "    pkg_power_W  = pkg_energy_J.diff().fillna(0).sum(axis=1) / dt  # Series length T\n",
    "\n",
    "    # 2) Identify fully‑idle timestamps (no core in C0 above threshold)\n",
    "    c0_res       = data[\"C0_norm_tsc_core\"]            # T×N fraction of time in C0\n",
    "    idle_mask    = (c0_res <= idle_thresh).all(axis=1) # Series length T (bool)\n",
    "\n",
    "    if idle_mask.sum() == 0:\n",
    "        raise RuntimeError(\"No fully‑idle samples found – choose higher idle_thresh.\")\n",
    "\n",
    "    # 3) Package idle power ➔ per‑core idle power\n",
    "    Ncores   = c0_res.shape[1]\n",
    "    pkg_idle = pkg_power_W[idle_mask].median()         # robust median Watts\n",
    "    bar_p    = pkg_idle / Ncores\n",
    "\n",
    "    return float(bar_p)\n",
    "\n",
    "\n",
    "# ───────────────────────  FREQUENCY CLUSTERING  ────────────────────────────\n",
    "def cluster_freq(\n",
    "    freq_raw: pd.DataFrame, n_states: int = 4, random_state: int = 0\n",
    ") -> tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Cluster per‑core normalized frequency into `n_states` bins.\n",
    "    Returns (clustered_df, sorted_centers).\n",
    "    \"\"\"\n",
    "    uniq = np.unique(freq_raw.values).reshape(-1, 1)\n",
    "    km = KMeans(n_clusters=n_states, random_state=random_state).fit(uniq)\n",
    "    centers = np.sort(km.cluster_centers_.flatten())\n",
    "\n",
    "    freq_c = freq_raw.copy().astype(float)\n",
    "    for col in freq_raw.columns:\n",
    "        freq_c[col] = centers[km.predict(freq_raw[col].values.reshape(-1, 1))]\n",
    "    return freq_c, centers\n",
    "\n",
    "\n",
    "# ───────────────  DERIVE f_ij & P_ij  ──────────────────────────────────────\n",
    "def derive_f_P(\n",
    "    power_df: pd.DataFrame,\n",
    "    freq_clustered: pd.DataFrame,\n",
    "    freq_levels: np.ndarray,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "      f_ij = mean effective frequency (Hz) of core i in DVFS state j\n",
    "      P_ij = mean power  (W)            of core i in DVFS state j\n",
    "    \"\"\"\n",
    "    cores = power_df.columns\n",
    "    f_ij = pd.DataFrame(index=cores, columns=freq_levels, dtype=float)\n",
    "    P_ij = pd.DataFrame(index=cores, columns=freq_levels, dtype=float)\n",
    "\n",
    "    for f in freq_levels:\n",
    "        mask = freq_clustered == f           # True where core is in that state\n",
    "        f_ij[f] = freq_clustered.where(mask).mean(axis=0)   # Hz\n",
    "        P_ij[f] = power_df.where(mask).mean(axis=0)         # W\n",
    "    return f_ij, P_ij\n",
    "\n",
    "\n",
    "# ────────────────  THERMAL CONDUCTANCE (GS)  ───────────────────────────────\n",
    "def estimate_GS(\n",
    "    temp_df: pd.DataFrame,\n",
    "    power_df: pd.DataFrame,\n",
    "    med_k: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return GS matrix (°C/W) using centered covariance / variance.\"\"\"\n",
    "    if med_k > 1:\n",
    "        temp_df = temp_df.apply(medfilt, kernel_size=med_k)\n",
    "\n",
    "    X = power_df.values - power_df.values.mean(0)\n",
    "    Y = temp_df.values - temp_df.values.mean(0)\n",
    "    T, N = X.shape\n",
    "\n",
    "    var = (X ** 2).mean(0)\n",
    "    cov = (X.T @ Y) / T\n",
    "    GS = cov.T / var[np.newaxis, :]\n",
    "    return pd.DataFrame(GS, index=temp_df.columns, columns=temp_df.columns)\n",
    "\n",
    "\n",
    "# ───────────────  ONE‑SHOT PIPELINE  ───────────────────────────────────────\n",
    "def process_round(\n",
    "    base_dir: str,\n",
    "    round_name: str = \"round0\",\n",
    "    n_states: int = 4,\n",
    "    dt: float = 0.5,\n",
    "    med_k: int = 3,\n",
    "    save_dir: str | None = None,\n",
    ") -> dict:\n",
    "\n",
    "    data  = load_round_pkl(base_dir, round_name)\n",
    "    cores = data[\"temp_core\"].columns\n",
    "\n",
    "    pkg_pw = package_power_watts(data, dt)\n",
    "    bar_p  = estimate_bar_p(data, dt)\n",
    "    p_core = per_core_power(pkg_pw, data, bar_p=bar_p, med_k=med_k)\n",
    "\n",
    "    # ---- use C0_norm_tsc_freq_core as the raw performance signal ----\n",
    "    freq_raw                 = data[\"C0_norm_tsc_freq_core\"]\n",
    "    freq_c, freq_centers     = cluster_freq(freq_raw, n_states)\n",
    "\n",
    "    # derive f_ij from frequency, P_ij from power\n",
    "    f_ij, P_ij = derive_f_P(\n",
    "        power_df       = p_core,\n",
    "        freq_clustered = freq_c,\n",
    "        freq_levels    = freq_centers,\n",
    "    )\n",
    "\n",
    "    GS = estimate_GS(data[\"temp_core\"], p_core, med_k=med_k)\n",
    "    Ta = data[\"temp_core\"].min(axis=0)\n",
    "\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        GS.to_csv(f\"{save_dir}/G_matrix.csv\", index=False)\n",
    "        P_ij.to_csv(f\"{save_dir}/Pij.csv\", index=False)\n",
    "        f_ij.to_csv(f\"{save_dir}/fij.csv\", index=False)\n",
    "        pd.DataFrame(Ta).to_csv(f\"{save_dir}/Ta_vector.csv\", header=False)\n",
    "\n",
    "    return {\n",
    "        \"GS\": GS,\n",
    "        \"P_ij\": P_ij,\n",
    "        \"f_ij\": f_ij,     # now measured in Hz\n",
    "        \"Ta\": Ta,\n",
    "        \"bar_p\": bar_p,\n",
    "        \"power_core\": p_core,\n",
    "        \"freq_clustered\": freq_c,\n",
    "        \"centers\": freq_centers,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ccfd1c-cb6a-41f3-a6f1-d0f3e379c635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MAR2_al/MAR2_hpl/65k_64_56/round0/preprocessing/round0.pkl\n"
     ]
    }
   ],
   "source": [
    "# ─── Example usage ─────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":  # run a quick sanity test\n",
    "    result = process_round(BASE_DIR, n_states=DVFS_STATES, save_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c8f2b7-d30a-4014-b6e0-cf156438f81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.018233163016183034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['bar_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d947715a-f7a0-451f-b3af-00420f622d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_ij diag median: 1.4249106724011767e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"P_ij diag median:\", np.median(np.diag(result[\"P_ij\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13be90c6-1271-41c1-a3a8-ab9f1d015f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS diag median (°C/W): 580.6516689348969\n"
     ]
    }
   ],
   "source": [
    "print(\"GS diag median (°C/W):\", np.median(np.diag(result[\"GS\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17118ea3-eea9-47c8-9c9b-27e58ae715a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0           1           2           3           4           5    \\\n",
      "min   367.429362  445.589474  377.148780  409.252728  428.791435  409.252728   \n",
      "mean  563.241349  628.836599  574.767527  599.714108  615.267213  599.714108   \n",
      "max   685.685637  763.565452  698.983701  730.718797  748.643628  730.718797   \n",
      "\n",
      "             6           7           8           9    ...         102  \\\n",
      "min   409.252728  409.252728  377.148780  409.252728  ...  367.429362   \n",
      "mean  599.714108  599.714108  574.767527  599.714108  ...  563.241349   \n",
      "max   730.718797  730.718797  698.983701  730.718797  ...  685.685637   \n",
      "\n",
      "             103         104         105         106         107         108  \\\n",
      "min   367.429362  367.429362  367.429982  367.429362  367.429362  367.429362   \n",
      "mean  563.241349  563.241349  563.242024  563.241349  563.241349  563.241349   \n",
      "max   685.685637  685.685637  685.686396  685.685637  685.685637  685.685637   \n",
      "\n",
      "             109         110         111  \n",
      "min   367.429362  367.429362  367.429362  \n",
      "mean  563.241349  563.241349  563.241349  \n",
      "max   685.685637  685.685637  685.685637  \n",
      "\n",
      "[3 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"GS\"].describe().loc[['min','mean','max']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
