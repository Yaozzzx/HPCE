{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2ca3c1-b849-464d-ae9e-e336be8217b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6caff19-58a8-4f8b-b42e-f92cf26354b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format, so each element\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea9f028-977f-4b00-860a-7fcf627955f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = '14'\n",
    "\n",
    "PICKLE_BASE_DIR = f\"../data/MAR2_al/MAR2_prbs_random/{cores}\"\n",
    "DATA_DIR        = f\"../results/{cores}/\"\n",
    "\n",
    "OUT_G           = f\"../results/{cores}/G_matrix.csv\"\n",
    "OUT_C           = f\"../results/{cores}/C_vector.csv\"\n",
    "OUT_b           = f\"../results/{cores}/b_vector.csv\"\n",
    "\n",
    "# Number of DVFS states to detect via clustering\n",
    "DVFS_STATES     = 3\n",
    "# Regression settings\n",
    "DELTA_SHIFT     = 1  # predict 1 step (0.5 s) ahead\n",
    "ALPHA           = 1.0\n",
    "# Placeholders for estimated idle/peak power\n",
    "IDLE_POWER      = None\n",
    "ASSUMED_PMAX    = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777527dc-ad47-4468-bb9f-9490ad3e9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── UTILITY FUNCTIONS ───────────────────────────────────────────────────────\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# ─── CHARACTERIZE Pij & fij FROM DATA ─────────────────────────────────────────\n",
    "def characterize_freq_states(pickle_base_dir, dvfs_states):\n",
    "    \"\"\"\n",
    "    Cluster freq_aperf_mperf_core into dvfs_states states, then compute\n",
    "    average power and performance per core per state.\n",
    "    Returns two dicts: P_FREQ and FREQ_PERF.\n",
    "    \"\"\"\n",
    "    util_list, power_list, perf_list = [], [], []\n",
    "    pattern = os.path.join(pickle_base_dir, \"round*\", \"preprocessing\", \"round*.pkl\")\n",
    "    for pkl_path in sorted(glob.glob(pattern)):\n",
    "        pkl = load_pickle(pkl_path)\n",
    "        util_df  = pkl[\"freq_aperf_mperf_core\"].astype(float)\n",
    "        util_df.index = pd.to_timedelta(util_df.index.astype(float), unit=\"s\")\n",
    "        power_df = compute_power_proxy(pkl)\n",
    "        perf_df  = pkl.get(\"aperf_core\").astype(float)\n",
    "        perf_df.index = util_df.index\n",
    "        util_list.append(util_df)\n",
    "        power_list.append(power_df)\n",
    "        perf_list.append(perf_df)\n",
    "    util_all  = pd.concat(util_list)\n",
    "    power_all = pd.concat(power_list)\n",
    "    perf_all  = pd.concat(perf_list)\n",
    "    interval = (util_all.index[1] - util_all.index[0]).total_seconds()\n",
    "    N = util_all.shape[1]\n",
    "\n",
    "    P_FREQ, FREQ_PERF = {}, {}\n",
    "    for i in range(N):\n",
    "        u = util_all.iloc[:, i].values.reshape(-1,1)\n",
    "        km = KMeans(n_clusters=dvfs_states, random_state=0).fit(u)\n",
    "        labels  = km.labels_\n",
    "        centers = km.cluster_centers_.flatten()\n",
    "        order   = np.argsort(centers)\n",
    "        mapping = {lab: state for state, lab in enumerate(order)}\n",
    "        P_FREQ[i], FREQ_PERF[i] = {}, {}\n",
    "        for lab, state in mapping.items():\n",
    "            mask = labels == lab\n",
    "            P_FREQ[i][state]    = float(power_all.iloc[:, i][mask].mean())\n",
    "            FREQ_PERF[i][state] = float(perf_all.iloc[:, i][mask].mean() / interval)\n",
    "    return P_FREQ, FREQ_PERF\n",
    "\n",
    "# ─── WRITE CHARACTERIZATION CSVs ───────────────────────────────────────────────\n",
    "def write_power_map(p_freq, out_file=DATA_DIR+\"Pij.csv\"):\n",
    "    df = pd.DataFrame(p_freq).T\n",
    "    df.index.name = \"core\"\n",
    "    df.columns.name = \"freq\"\n",
    "    df.to_csv(out_file)\n",
    "    print(f\"[char] wrote power map to {out_file}\")\n",
    "\n",
    "def write_perf_map(freq_perf, out_file=DATA_DIR+\"fij.csv\"):\n",
    "    df = pd.DataFrame(freq_perf).T\n",
    "    df.index.name = \"core\"\n",
    "    df.columns.name = \"freq\"\n",
    "    df.to_csv(out_file)\n",
    "    print(f\"[char] wrote perf map to {out_file}\")\n",
    "\n",
    "def write_Tprev(data_dir, out_file=DATA_DIR+\"Tprev_vec.csv\"):\n",
    "    files = sorted(glob.glob(os.path.join(data_dir, \"round*_combined.csv\")))\n",
    "    if not files:\n",
    "        print(\"[char] No combined CSVs found for Tprev extraction.\")\n",
    "        return\n",
    "    df = pd.read_csv(files[-1], index_col=0)\n",
    "    temp_cols = [c for c in df.columns if c.startswith(\"T_core_\")]\n",
    "    last = df[temp_cols].iloc[-1]\n",
    "    pd.Series(last.values).to_csv(out_file, index=False, header=False)\n",
    "    print(f\"[char] wrote Tprev vector to {out_file}\")\n",
    "\n",
    "# ─── POWER PROXY & TIMESERIES PREP ─────────────────────────────────────────────\n",
    "def estimate_idle_and_pmax(pickle_base_dir, pct=(0.05,0.95)):\n",
    "    per_core_pw = []\n",
    "    n_cores = None\n",
    "    pattern = os.path.join(pickle_base_dir, \"round*\", \"preprocessing\", \"round*.pkl\")\n",
    "    for pkl_path in sorted(glob.glob(pattern)):\n",
    "        pkl = load_pickle(pkl_path)\n",
    "        pkg = pkl.get(\"power_from_erg_pkg_cpu\")\n",
    "        if pkg is None:\n",
    "            continue\n",
    "        pkg = pkg.astype(float)\n",
    "        if n_cores is None:\n",
    "            n_cores = pkl.get(\"temp_core\").shape[1]\n",
    "        avg_core = pkg.sum(axis=1) / n_cores\n",
    "        per_core_pw.append(avg_core)\n",
    "    all_pw = pd.concat(per_core_pw)\n",
    "    idle, peak = all_pw.quantile(pct).values\n",
    "    return float(idle), float(peak)\n",
    "\n",
    "def compute_power_proxy(pkl):\n",
    "    util = pkl[\"freq_aperf_mperf_core\"].astype(float)\n",
    "    return IDLE_POWER + (ASSUMED_PMAX - IDLE_POWER) * util\n",
    "\n",
    "def ensure_timedelta_index(df):\n",
    "    if not isinstance(df.index, (pd.DatetimeIndex, pd.TimedeltaIndex)):\n",
    "        df = df.copy()\n",
    "        df.index = pd.to_timedelta(df.index.astype(float), unit=\"s\")\n",
    "    return df\n",
    "\n",
    "def resample_df(df, freq=\"500ms\"):\n",
    "    df = ensure_timedelta_index(df)\n",
    "    return df.resample(freq).mean().interpolate()\n",
    "\n",
    "def process_round_to_csv(pkl_path):\n",
    "    pkl   = load_pickle(pkl_path)\n",
    "    temp  = pkl[\"temp_core\"]\n",
    "    power = compute_power_proxy(pkl)\n",
    "    t_rs  = resample_df(temp)\n",
    "    p_rs  = resample_df(power)\n",
    "    t_rs.columns = [f\"T_core_{c}\" for c in t_rs.columns]\n",
    "    p_rs.columns = [f\"P_core_{c}\" for c in p_rs.columns]\n",
    "    df    = pd.concat([p_rs, t_rs], axis=1)\n",
    "    rnd   = os.path.basename(os.path.dirname(os.path.dirname(pkl_path)))\n",
    "    out   = os.path.join(DATA_DIR, f\"{rnd}_combined.csv\")\n",
    "    df.to_csv(out, index_label=\"time_s\")\n",
    "    print(f\"[prep] wrote {out}\")\n",
    "\n",
    "def prepare_combined_csvs():\n",
    "    pattern = os.path.join(PICKLE_BASE_DIR, \"round*\", \"preprocessing\", \"round*.pkl\")\n",
    "    for pkl_path in sorted(glob.glob(pattern)):\n",
    "        rnd  = os.path.basename(os.path.dirname(os.path.dirname(pkl_path)))\n",
    "        csvp = os.path.join(DATA_DIR, f\"{rnd}_combined.csv\")\n",
    "        if not os.path.exists(csvp):\n",
    "            process_round_to_csv(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090ad917-4101-455c-a7f0-1ae5e9acc0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_csvs():\n",
    "    files = sorted(glob.glob(os.path.join(DATA_DIR, \"round*_combined.csv\")))\n",
    "    dfs   = []\n",
    "    for fpath in files:\n",
    "        df = pd.read_csv(fpath, index_col=0)\n",
    "        # parse index strings as Timedelta\n",
    "        df.index = pd.to_timedelta(df.index)\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def fit_core(df, core_idx, delta=1, alpha=1.0):\n",
    "    P_cols = [c for c in df.columns if c.startswith(\"P_core_\")]\n",
    "    T_col  = f\"T_core_{core_idx}\"\n",
    "    X      = df[P_cols].copy()\n",
    "    X[T_col] = df[T_col]\n",
    "    y       = df[T_col].shift(-delta)\n",
    "    valid   = y.notna()\n",
    "    X_train = X.loc[valid]\n",
    "    y_train = y.loc[valid]\n",
    "    X_train = X_train.loc[:, X_train.var() > 0]\n",
    "    model   = Ridge(alpha=alpha, fit_intercept=True).fit(X_train, y_train)\n",
    "    full    = np.zeros(len(P_cols)+1)\n",
    "    kept    = list(X_train.columns)\n",
    "    for coef, name in zip(model.coef_, kept):\n",
    "        idx = P_cols.index(name) if name in P_cols else len(P_cols)\n",
    "        full[idx] = coef\n",
    "    return full[:len(P_cols)], full[len(P_cols)], model.intercept_\n",
    "\n",
    "def fit_and_save():\n",
    "    df = load_all_csvs()\n",
    "    N  = len([c for c in df if c.startswith(\"P_core_\")])\n",
    "    G  = np.zeros((N, N)); C = np.zeros(N); b = np.zeros(N)\n",
    "    for ℓ in range(N):\n",
    "        G_l, C_l, b_l = fit_core(df, ℓ, DELTA_SHIFT, ALPHA)\n",
    "        G[ℓ,:], C[ℓ], b[ℓ] = G_l, C_l, b_l\n",
    "        print(f\"[fit] core {ℓ}: C={C_l:.4f}, b={b_l:.4f}\")\n",
    "    pd.DataFrame(G).to_csv(OUT_G, index=False)\n",
    "    pd.Series(C).to_csv(OUT_C, index=False)\n",
    "    pd.Series(b).to_csv(OUT_b, index=False)\n",
    "    print(f\"[fit] wrote {OUT_G}, {OUT_C}, {OUT_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186146f1-d963-4c88-8462-4445705044ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated idle: 2.51 W, peak: 2.83 W\n",
      "[char] wrote power map to ../results/14/Pij.csv\n",
      "[char] wrote perf map to ../results/14/fij.csv\n",
      "[prep] wrote ../results/14/round0_combined.csv\n",
      "[prep] wrote ../results/14/round1_combined.csv\n",
      "[prep] wrote ../results/14/round2_combined.csv\n",
      "[prep] wrote ../results/14/round3_combined.csv\n",
      "[prep] wrote ../results/14/round4_combined.csv\n",
      "[char] wrote Tprev vector to ../results/14/Tprev_vec.csv\n",
      "[fit] core 0: C=0.7355, b=34.3821\n",
      "[fit] core 1: C=0.7220, b=63.8480\n",
      "[fit] core 2: C=0.6312, b=75.1672\n",
      "[fit] core 3: C=0.7108, b=40.3571\n",
      "[fit] core 4: C=0.5342, b=281.0337\n",
      "[fit] core 5: C=0.6018, b=103.4587\n",
      "[fit] core 6: C=0.7336, b=30.5207\n",
      "[fit] core 7: C=0.7107, b=73.2134\n",
      "[fit] core 8: C=0.6383, b=182.4365\n",
      "[fit] core 9: C=0.6498, b=56.2087\n",
      "[fit] core 10: C=0.7037, b=45.7806\n",
      "[fit] core 11: C=0.7263, b=25.4633\n",
      "[fit] core 12: C=0.6201, b=162.4883\n",
      "[fit] core 13: C=0.6323, b=93.0927\n",
      "[fit] core 14: C=0.7064, b=63.2315\n",
      "[fit] core 15: C=0.6811, b=97.7325\n",
      "[fit] core 16: C=0.7270, b=36.9331\n",
      "[fit] core 17: C=0.6924, b=65.8799\n",
      "[fit] core 18: C=0.6517, b=105.4098\n",
      "[fit] core 19: C=0.6639, b=44.9925\n",
      "[fit] core 20: C=0.7400, b=58.6945\n",
      "[fit] core 21: C=0.6654, b=26.3938\n",
      "[fit] core 22: C=0.7733, b=34.2232\n",
      "[fit] core 23: C=0.6885, b=33.4614\n",
      "[fit] core 24: C=0.7330, b=30.6179\n",
      "[fit] core 25: C=0.7777, b=17.1245\n",
      "[fit] core 26: C=0.7395, b=4.8852\n",
      "[fit] core 27: C=0.6793, b=87.0834\n",
      "[fit] core 28: C=0.6210, b=-12.6549\n",
      "[fit] core 29: C=0.5680, b=24.2312\n",
      "[fit] core 30: C=0.7627, b=-8.2487\n",
      "[fit] core 31: C=0.6964, b=94.0417\n",
      "[fit] core 32: C=0.5575, b=119.2493\n",
      "[fit] core 33: C=0.6804, b=26.5572\n",
      "[fit] core 34: C=0.7314, b=21.5217\n",
      "[fit] core 35: C=0.6582, b=88.2964\n",
      "[fit] core 36: C=0.7083, b=81.3758\n",
      "[fit] core 37: C=0.6280, b=111.4729\n",
      "[fit] core 38: C=0.6502, b=50.5772\n",
      "[fit] core 39: C=0.6703, b=76.1109\n",
      "[fit] core 40: C=0.6755, b=25.8505\n",
      "[fit] core 41: C=0.6489, b=118.8543\n",
      "[fit] core 42: C=0.6381, b=65.0508\n",
      "[fit] core 43: C=0.5958, b=60.8300\n",
      "[fit] core 44: C=0.6108, b=99.5239\n",
      "[fit] core 45: C=0.7720, b=19.3780\n",
      "[fit] core 46: C=0.7126, b=32.2640\n",
      "[fit] core 47: C=0.6420, b=47.2795\n",
      "[fit] core 48: C=0.6132, b=109.8886\n",
      "[fit] core 49: C=0.6946, b=33.9729\n",
      "[fit] core 50: C=0.7664, b=22.4378\n",
      "[fit] core 51: C=0.6780, b=32.7367\n",
      "[fit] core 52: C=0.6619, b=97.1420\n",
      "[fit] core 53: C=0.6519, b=56.3439\n",
      "[fit] core 54: C=0.6195, b=51.3201\n",
      "[fit] core 55: C=0.7098, b=18.5131\n",
      "[fit] core 56: C=0.6018, b=55.6233\n",
      "[fit] core 57: C=0.7145, b=38.3931\n",
      "[fit] core 58: C=0.6895, b=41.2721\n",
      "[fit] core 59: C=0.7451, b=58.2654\n",
      "[fit] core 60: C=0.7113, b=1.7352\n",
      "[fit] core 61: C=0.6782, b=-11.7859\n",
      "[fit] core 62: C=0.7596, b=23.1301\n",
      "[fit] core 63: C=0.7241, b=17.7909\n",
      "[fit] core 64: C=0.7401, b=31.4085\n",
      "[fit] core 65: C=0.7364, b=6.5224\n",
      "[fit] core 66: C=0.7863, b=31.7794\n",
      "[fit] core 67: C=0.7690, b=11.3858\n",
      "[fit] core 68: C=0.7379, b=3.1619\n",
      "[fit] core 69: C=0.7154, b=41.9587\n",
      "[fit] core 70: C=0.7708, b=16.3953\n",
      "[fit] core 71: C=0.6540, b=0.2813\n",
      "[fit] core 72: C=0.7046, b=63.0783\n",
      "[fit] core 73: C=0.7379, b=14.6921\n",
      "[fit] core 74: C=0.6881, b=-7.1668\n",
      "[fit] core 75: C=0.5724, b=40.5440\n",
      "[fit] core 76: C=0.7330, b=17.6319\n",
      "[fit] core 77: C=0.6650, b=-7.7866\n",
      "[fit] core 78: C=0.7370, b=-8.0227\n",
      "[fit] core 79: C=0.7801, b=3.5282\n",
      "[fit] core 80: C=0.7206, b=33.8726\n",
      "[fit] core 81: C=0.5677, b=39.1565\n",
      "[fit] core 82: C=0.7381, b=-2.9424\n",
      "[fit] core 83: C=0.7425, b=-3.2843\n",
      "[fit] core 84: C=0.7249, b=29.3175\n",
      "[fit] core 85: C=0.5767, b=57.1203\n",
      "[fit] core 86: C=0.6254, b=45.0255\n",
      "[fit] core 87: C=0.6015, b=46.5364\n",
      "[fit] core 88: C=0.5847, b=15.5287\n",
      "[fit] core 89: C=0.6735, b=15.0506\n",
      "[fit] core 90: C=0.6791, b=9.5358\n",
      "[fit] core 91: C=0.7344, b=-0.7996\n",
      "[fit] core 92: C=0.6279, b=43.6831\n",
      "[fit] core 93: C=0.6383, b=54.7842\n",
      "[fit] core 94: C=0.6163, b=19.7196\n",
      "[fit] core 95: C=0.7300, b=12.2793\n",
      "[fit] core 96: C=0.5785, b=11.5537\n",
      "[fit] core 97: C=0.7490, b=14.2903\n",
      "[fit] core 98: C=0.7287, b=24.1627\n",
      "[fit] core 99: C=0.6747, b=43.0261\n",
      "[fit] core 100: C=0.5033, b=134.0991\n",
      "[fit] core 101: C=0.7028, b=21.8727\n",
      "[fit] core 102: C=0.6844, b=1.9442\n",
      "[fit] core 103: C=0.6928, b=-16.7435\n",
      "[fit] core 104: C=0.6397, b=48.2281\n",
      "[fit] core 105: C=0.7154, b=24.0575\n",
      "[fit] core 106: C=0.6515, b=63.9340\n",
      "[fit] core 107: C=0.7303, b=34.3302\n",
      "[fit] core 108: C=0.7152, b=-0.6531\n",
      "[fit] core 109: C=0.6992, b=20.6166\n",
      "[fit] core 110: C=0.4450, b=138.5031\n",
      "[fit] core 111: C=0.7126, b=42.2814\n",
      "[fit] wrote ../results/14/G_matrix.csv, ../results/14/C_vector.csv, ../results/14/b_vector.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ensure_dirs()\n",
    "    # estimate idle/peak power\n",
    "    idle, peak = estimate_idle_and_pmax(PICKLE_BASE_DIR)\n",
    "    print(f\"Estimated idle: {idle:.2f} W, peak: {peak:.2f} W\")\n",
    "    IDLE_POWER, ASSUMED_PMAX = idle, peak\n",
    "    \n",
    "    # auto-populate Pij and fij\n",
    "    if DVFS_STATES > 0:\n",
    "        P_FREQ, FREQ_PERF = characterize_freq_states(PICKLE_BASE_DIR, DVFS_STATES)\n",
    "        write_power_map(P_FREQ)\n",
    "        write_perf_map(FREQ_PERF)\n",
    "    \n",
    "    # prepare combined timeseries\n",
    "    prepare_combined_csvs()\n",
    "    # extract last temperatures\n",
    "    write_Tprev(DATA_DIR)\n",
    "    # fit thermal model\n",
    "    fit_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb45b3f-48a7-4ad7-a62b-692eb7b2ba10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a2290-e4e0-4cd4-a132-fb7d59fdba76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f29f4-d728-4d95-b37b-ded63f24252c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c0864-37a7-40ea-aae5-cba0fbbfe330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
